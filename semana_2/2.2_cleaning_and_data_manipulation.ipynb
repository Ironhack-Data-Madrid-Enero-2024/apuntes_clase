{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1_pandas.ipynb\r\n",
      "2.2_cleaning_and_data_manipulation.ipynb\r\n",
      "2.3_combining_structuring_data.ipynb\r\n",
      "\u001b[31m2.4_aggregating_data.ipynb\u001b[m\u001b[m*\r\n",
      "2.5_apis.ipynb\r\n",
      "2.6_web_scraping.ipynb\r\n",
      "data.pkl\r\n",
      "tablita.csv\r\n",
      "tablita.xlsx\r\n",
      "tiburones.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tiburones.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>...</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>New York</td>\n",
       "      <td>Beach 3, Robert Moses State Park, Suffolk County</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>female</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>13h45</td>\n",
       "      <td>Sand tiger shark</td>\n",
       "      <td>S.S. Curatolo- Wagemann, GSAFF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-17</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Questionable</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Quintana Roo</td>\n",
       "      <td>Cancún</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Dillon Armijo</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Authorities report injury caused bya barracuda</td>\n",
       "      <td>Denver7, 3/29/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>KNZ</td>\n",
       "      <td>Protea Banks</td>\n",
       "      <td>Diving/Shark Feeding</td>\n",
       "      <td>Ranier Kruger</td>\n",
       "      <td>M</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>09h00</td>\n",
       "      <td>Blacktip</td>\n",
       "      <td>A Currie, GSAF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-16</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Daytona Beach Shores, Volusia County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tasa Summers</td>\n",
       "      <td>F</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>13h12</td>\n",
       "      <td>A small shark</td>\n",
       "      <td>WESH, 717,2022</td>\n",
       "      <td>2022.07.16-Summers.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2022.07.16</td>\n",
       "      <td>2022.07.16</td>\n",
       "      <td>6785.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>EGYPT</td>\n",
       "      <td>Hurghada, Red Sea Governorate</td>\n",
       "      <td>Sahl Hasheesh</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Elisabeth Sauer</td>\n",
       "      <td>F</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oceaniic whitetip shark/tiger shark, 2m shark</td>\n",
       "      <td>M. Michaeilson, GSAF</td>\n",
       "      <td>2022.07.01.a-Sauer.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2022.07.01.a</td>\n",
       "      <td>2022.07.01.a</td>\n",
       "      <td>6775.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Year          Type       Country  \\\n",
       "0  2023-07-03  2023.0    Unprovoked           USA   \n",
       "1  2023-03-17  2023.0  Questionable        MEXICO   \n",
       "2  2022-12-30  2022.0      Provoked  South Africa   \n",
       "3  2022-07-16  2022.0    Unprovoked           USA   \n",
       "4  2022-07-01  2022.0    Unprovoked         EGYPT   \n",
       "\n",
       "                            Area  \\\n",
       "0                       New York   \n",
       "1                   Quintana Roo   \n",
       "2                            KNZ   \n",
       "3                        Florida   \n",
       "4  Hurghada, Red Sea Governorate   \n",
       "\n",
       "                                           Location              Activity  \\\n",
       "0  Beach 3, Robert Moses State Park, Suffolk County              Swimming   \n",
       "1                                            Cancún              Swimming   \n",
       "2                                      Protea Banks  Diving/Shark Feeding   \n",
       "3              Daytona Beach Shores, Volusia County                   NaN   \n",
       "4                                     Sahl Hasheesh              Swimming   \n",
       "\n",
       "              Name Sex    Age  ... Fatal (Y/N)   Time  \\\n",
       "0           female    F    15  ...           N  13h45   \n",
       "1    Dillon Armijo    M    10  ...           N    NaN   \n",
       "2    Ranier Kruger    M    26  ...           N  09h00   \n",
       "3     Tasa Summers    F  40.0  ...           N  13h12   \n",
       "4  Elisabeth Sauer    F  68.0  ...           Y    NaN   \n",
       "\n",
       "                                         Species   \\\n",
       "0                                Sand tiger shark   \n",
       "1  Authorities report injury caused bya barracuda   \n",
       "2                                        Blacktip   \n",
       "3                                   A small shark   \n",
       "4   Oceaniic whitetip shark/tiger shark, 2m shark   \n",
       "\n",
       "           Investigator or Source                     pdf  \\\n",
       "0  S.S. Curatolo- Wagemann, GSAFF                     NaN   \n",
       "1              Denver7, 3/29/2023                     NaN   \n",
       "2                  A Currie, GSAF                     NaN   \n",
       "3                  WESH, 717,2022  2022.07.16-Summers.pdf   \n",
       "4            M. Michaeilson, GSAF  2022.07.01.a-Sauer.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href   Case Number  \\\n",
       "0                                                NaN           NaN   \n",
       "1                                                NaN           NaN   \n",
       "2                                                NaN           NaN   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...    2022.07.16   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...  2022.07.01.a   \n",
       "\n",
       "  Case Number.1 original order  \n",
       "0           NaN            NaN  \n",
       "1           NaN            NaN  \n",
       "2           NaN            NaN  \n",
       "3    2022.07.16         6785.0  \n",
       "4  2022.07.01.a         6775.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGqBhnEYCnFb",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Cleaning-Data\" data-toc-modified-id=\"Cleaning-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Cleaning Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Null-values\" data-toc-modified-id=\"Null-values-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Null values</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cleaning-Null-Values\" data-toc-modified-id=\"Cleaning-Null-Values-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Cleaning Null Values</a></span></li><li><span><a href=\"#Checking-for-Null-Values\" data-toc-modified-id=\"Checking-for-Null-Values-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Checking for Null Values</a></span></li><li><span><a href=\"#Dropping-Null-Values\" data-toc-modified-id=\"Dropping-Null-Values-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Dropping Null Values</a></span></li><li><span><a href=\"#Filling-Null-Values\" data-toc-modified-id=\"Filling-Null-Values-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Filling Null Values</a></span></li><li><span><a href=\"#💡-Check-for-understanding\" data-toc-modified-id=\"💡-Check-for-understanding-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>💡 Check for understanding</a></span></li></ul></li><li><span><a href=\"#Dealing-with-Duplicates\" data-toc-modified-id=\"Dealing-with-Duplicates-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Dealing with Duplicates</a></span><ul class=\"toc-item\"><li><span><a href=\"#Identifying-Duplicates\" data-toc-modified-id=\"Identifying-Duplicates-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Identifying Duplicates</a></span></li><li><span><a href=\"#Removing-Duplicates\" data-toc-modified-id=\"Removing-Duplicates-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Removing Duplicates</a></span></li><li><span><a href=\"#Removing-Duplicates-Based-on-Specific-Columns\" data-toc-modified-id=\"Removing-Duplicates-Based-on-Specific-Columns-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Removing Duplicates Based on Specific Columns</a></span></li><li><span><a href=\"#Resetting-the-Index\" data-toc-modified-id=\"Resetting-the-Index-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Resetting the Index</a></span></li></ul></li><li><span><a href=\"#Formatting-Data\" data-toc-modified-id=\"Formatting-Data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Formatting Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Formatting-Numeric-Values\" data-toc-modified-id=\"Formatting-Numeric-Values-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Formatting Numeric Values</a></span></li><li><span><a href=\"#Formatting-Strings\" data-toc-modified-id=\"Formatting-Strings-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Formatting Strings</a></span></li><li><span><a href=\"#Formatting-Dates\" data-toc-modified-id=\"Formatting-Dates-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Formatting Dates</a></span></li></ul></li><li><span><a href=\"#Cleaning-Column-Names\" data-toc-modified-id=\"Cleaning-Column-Names-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Cleaning Column Names</a></span></li></ul></li><li><span><a href=\"#Using-apply(),-map(),-and-applymap()\" data-toc-modified-id=\"Using-apply(),-map(),-and-applymap()-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Using <code>apply()</code>, <code>map()</code>, and <code>applymap()</code></a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Apply()\" data-toc-modified-id=\"Apply()-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span><code>Apply()</code></a></span></li><li><span><a href=\"#Map()\" data-toc-modified-id=\"Map()-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span><code>Map()</code></a></span></li><li><span><a href=\"#applyMap()\" data-toc-modified-id=\"applyMap()-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span><code>applyMap()</code></a></span></li><li><span><a href=\"#More-examples\" data-toc-modified-id=\"More-examples-2.0.4\"><span class=\"toc-item-num\">2.0.4&nbsp;&nbsp;</span>More examples</a></span><ul class=\"toc-item\"><li><span><a href=\"#Comparing-Map-and-Apply\" data-toc-modified-id=\"Comparing-Map-and-Apply-2.0.4.1\"><span class=\"toc-item-num\">2.0.4.1&nbsp;&nbsp;</span>Comparing Map and Apply</a></span></li><li><span><a href=\"#Calculating-the-length-of-the-name\" data-toc-modified-id=\"Calculating-the-length-of-the-name-2.0.4.2\"><span class=\"toc-item-num\">2.0.4.2&nbsp;&nbsp;</span>Calculating the length of the name</a></span></li><li><span><a href=\"#Converting-to-float-some-columns-with-applymap()\" data-toc-modified-id=\"Converting-to-float-some-columns-with-applymap()-2.0.4.3\"><span class=\"toc-item-num\">2.0.4.3&nbsp;&nbsp;</span>Converting to float some columns with applymap()</a></span></li><li><span><a href=\"#Modifying-cloumns-names-with-apply()\" data-toc-modified-id=\"Modifying-cloumns-names-with-apply()-2.0.4.4\"><span class=\"toc-item-num\">2.0.4.4&nbsp;&nbsp;</span>Modifying cloumns names with apply()</a></span></li></ul></li><li><span><a href=\"#💡-Check-for-understanding\" data-toc-modified-id=\"💡-Check-for-understanding-2.0.5\"><span class=\"toc-item-num\">2.0.5&nbsp;&nbsp;</span>💡 Check for understanding</a></span></li><li><span><a href=\"#💡-Check-for-understanding\" data-toc-modified-id=\"💡-Check-for-understanding-2.0.6\"><span class=\"toc-item-num\">2.0.6&nbsp;&nbsp;</span>💡 Check for understanding</a></span></li></ul></li></ul></li><li><span><a href=\"#Filtering-Data\" data-toc-modified-id=\"Filtering-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Filtering Data</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-condition\" data-toc-modified-id=\"Creating-a-condition-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Creating a condition</a></span></li><li><span><a href=\"#Filtering-df\" data-toc-modified-id=\"Filtering-df-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Filtering df</a></span></li><li><span><a href=\"#Using-multiple-conditions\" data-toc-modified-id=\"Using-multiple-conditions-3.0.3\"><span class=\"toc-item-num\">3.0.3&nbsp;&nbsp;</span>Using multiple conditions</a></span></li></ul></li></ul></li><li><span><a href=\"#More-Data-Manipulation\" data-toc-modified-id=\"More-Data-Manipulation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>More Data Manipulation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setting-the-index\" data-toc-modified-id=\"Setting-the-index-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Setting the index</a></span></li><li><span><a href=\"#Adding/removing-rows-and/or-columns\" data-toc-modified-id=\"Adding/removing-rows-and/or-columns-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Adding/removing rows and/or columns</a></span></li><li><span><a href=\"#💡-Check-for-understanding\" data-toc-modified-id=\"💡-Check-for-understanding-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>💡 Check for understanding</a></span></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioL4qYxaCnFi",
    "tags": []
   },
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gz7aV8e9CnFj"
   },
   "source": [
    "## Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vjLBgJACnFj"
   },
   "source": [
    "Null values (also known as missing values) are common in datasets and can hinder data analysis and modeling. It is essential to handle null values appropriately to ensure accurate and reliable results. Pandas provides various methods to clean and handle null values in datasets.\n",
    "\n",
    "In Python, `None` is a special constant that represents the absence of a value. It is commonly used to indicate that a variable or function has no value or hasn't been assigned any value. For example, if a function does not explicitly return a value, it implicitly returns `None`.\n",
    "\n",
    "On the other hand, `NaN` stands for \"Not a Number\" and is a special value used to represent missing or undefined numerical data. `NaN` is part of the floating-point representation and is commonly used in numeric data structures like Pandas DataFrames and Series to indicate missing or invalid numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZVn3rnCCnFj"
   },
   "source": [
    "\n",
    "\n",
    "### Cleaning Null Values\n",
    "\n",
    "1. Checking for Null Values:\n",
    "   - Use `isnull()` method to check for null values in a DataFrame or Series.\n",
    "   - Use `notnull()` method to check for non-null values in a DataFrame or Series.\n",
    "\n",
    "2. Dropping Null Values:\n",
    "   - Use `dropna()` method to remove rows with null values from a DataFrame.\n",
    "   - Use `dropna(axis=1)` to remove columns with null values.\n",
    "\n",
    "3. Filling Null Values:\n",
    "   - Use `fillna(value)` method to replace null values with a specific value.\n",
    "   - Use `fillna(method='ffill')` to forward-fill null values with the previous non-null value.\n",
    "   - Use `fillna(method='bfill')` to backward-fill null values with the next non-null value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPKEhg5aCnFj"
   },
   "source": [
    "### Checking for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqjVuWlkCnFj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Titanic dataset from an online source\n",
    "url = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/titanic_train.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8HjY_ZZCnFk"
   },
   "source": [
    "When working with large datasets, using `isna()` or `isnull()` along with `any()` and `sum()` in Pandas becomes essential for quick and efficient data quality assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SmMfg6NCnFk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG6ZmrBVCnFk"
   },
   "source": [
    "sum() calculates the sum of each row, considering True as 1 and False as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ktKBrP1CnFk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4xsvxUbCnFk"
   },
   "source": [
    "If we add the parameter `axis=1` with the `sum()` function, we can calculate the sum of each row (along the columns) of the DataFrame `df`. This results in a Series that contains the count of null values in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ytT0UjZpCnFk",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58UdOIKQCnFk"
   },
   "source": [
    "### Dropping Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFwax3J5CnFk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZSKOoH9CnFk"
   },
   "source": [
    "However, as we can see below in the DataFrame, the rows with NaN values have not been removed. To execute the change, it is necessary to use the `inplace=True` option: `df.dropna(inplace=True)` or assign it to a variable such as df = df.dropna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCYfJnETCnFl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJ9Hq-AQCnFl"
   },
   "source": [
    "In the `dropna()` method of Pandas DataFrame, the `subset`, `how`, and `thresh` parameters are used to control the behavior of dropping rows or columns containing NaN (null) values, when we don't want to drop them just because they have *one* null value:\n",
    "\n",
    "- `subset`: It allows you to specify a subset of columns on which to apply the `dropna()` operation. Only the rows containing NaN values in the specified subset of columns will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbhWzPAmCnFl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zNFOr2qCnFl"
   },
   "source": [
    "- `how`: It specifies the condition for dropping rows. It can take the values 'any', which means to drop rows containing any NaN values in the `subset`, or 'all', which means to drop rows containing all NaN values in the `subset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEb3JcEcCnFl",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8oyNUapCnFl"
   },
   "source": [
    "- `thresh`: It sets a minimum threshold for the number of non-null values that a row must have in the `subset` in order to be kept. Rows with fewer non-null values than the specified threshold will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOz2ftkaCnFl",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcM36B3YCnFl"
   },
   "source": [
    "### Filling Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1AoyfsqCnFl"
   },
   "source": [
    "`fillna()` is a Pandas method used to replace NaN (null) values in a DataFrame or Series with specified values.\n",
    "- You can use `inplace=True` to modify the DataFrame directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ii3bX0R2CnFl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8MXBPxBOCnFm"
   },
   "source": [
    "Careful if we assign a different data type, since Pandas will change the data type of the whole column. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cp490ltNCnFm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRlDc2uUCnFm"
   },
   "source": [
    "To avoid this, we can select manually in which column to apply the `fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2uTvGbIYCnFm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0Qf6TyeCnFm"
   },
   "source": [
    "We can also use the mean(), median() etc. to fill the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qz-LeDO3CnFm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8sazPSlCnFm"
   },
   "source": [
    "- Two common methods for filling NaN values are `ffill`, which forward fills using the last valid value, and `bfill`, which backward fills using the next valid value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9iGVMC_CnFm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E45QKUddCnFm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQuimxxHCnFm"
   },
   "source": [
    "## Dealing with Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNO-MV7oCnFm"
   },
   "source": [
    "In data analysis, it's common to encounter duplicate values in datasets. Duplicates can distort our analysis and lead to incorrect conclusions. Fortunately, pandas provides efficient methods to handle duplicates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoklfHUPCnFm"
   },
   "source": [
    "### Identifying Duplicates\n",
    "\n",
    "To identify duplicate rows in a DataFrame, we can use the `duplicated()` method, which returns a boolean Series indicating whether each row is a duplicate or not. We can then use the `sum()` method to count the total number of duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QQa4lKwCnFm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AriiG9BWCnFm"
   },
   "source": [
    "To check for duplicates in specific columns, we can use the `duplicated()` method with the `subset` parameter, or just access first to the column and then check with duplicated().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjsS5YvUCnFn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duEie7BWCnFn"
   },
   "source": [
    "### Removing Duplicates\n",
    "\n",
    "To remove duplicates from a DataFrame, we can use the `drop_duplicates()` method. By default, this method keeps the first occurrence of each duplicated row and removes the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yO4crWttCnFn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXuHZocACnFn"
   },
   "source": [
    "### Removing Duplicates Based on Specific Columns\n",
    "\n",
    "Sometimes, we may want to remove duplicates based on specific columns. We can pass a subset of column names to the `drop_duplicates()` method to achieve this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KY_kN0JUCnFn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAI4qDbkCnFn"
   },
   "source": [
    "By default, `drop_duplicates()` keeps the first occurrence of each duplicated row. If we want to keep the last occurrence instead, we can set the `keep` parameter to `'last'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ke90ERAZCnFn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5_Rq7K4CnFn"
   },
   "source": [
    "### Resetting the Index\n",
    "\n",
    "When removing duplicates, the DataFrame index may have gaps due to removed rows. To reset the index after removing duplicates, we can use the `reset_index()` method with the `drop=True` parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWyQE6QmCnFn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47RNvr1oCnFn"
   },
   "source": [
    "## Formatting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wySkx2BzCnFn"
   },
   "source": [
    "### Formatting Numeric Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbeVX4rbCnFn"
   },
   "source": [
    "\n",
    "1. `round()` Method:\n",
    "   - Rounds numeric values to a specified number of decimal places.\n",
    "\n",
    "2. `format()` Method:\n",
    "   - Formats numeric values as strings for better representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kvMeXWPUCnFn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Pksit9zCnFn"
   },
   "source": [
    "### Formatting Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQTsR2bCCnFn"
   },
   "source": [
    "Check the data structures lesson for more string operations and formatting. Here we'll just look at some of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycnKst6nCnFn"
   },
   "source": [
    "1. **Using f-strings (formatted string literals):**\n",
    "   - f-strings are introduced in Python 3.6 and provide a concise and readable way to format strings.\n",
    "   - Place variables or expressions inside curly braces `{}` in the string, preceded by the `f` character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_ID5AkkCnFo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwCh85leCnFo"
   },
   "source": [
    "2. **Using the `format()` method:**\n",
    "   - The `format()` method can be applied to a string and accepts positional or keyword arguments to replace placeholders.\n",
    "   - Placeholders are represented by curly braces `{}` and can be indexed or named."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svFVyYtaCnFo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28IchMDKCnFo"
   },
   "source": [
    "3. **Using `%` formatting:**\n",
    "   - `%` formatting is an older method, similar to C-style formatting, but less recommended due to its limitations and lack of flexibility.\n",
    "   - Placeholders are represented by `%` followed by format specifiers, like `%s` for strings and `%d` for integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KIqR0QoCnFo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiMrwCIcCnFo"
   },
   "source": [
    "Let's look at some methods for formatting strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxtvFGH3CnFo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "graExqxhCnFo"
   },
   "source": [
    "### Formatting Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aelVutGQCnFo"
   },
   "source": [
    "We will study this in another Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EpuHyJ1CnFo",
    "tags": []
   },
   "source": [
    "## Cleaning Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKs75zMdCnFp"
   },
   "source": [
    "We can acccess the columns using `df.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwMlk5YgCnFp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4H2drqaCnFp"
   },
   "source": [
    "In order to modify them, we can assign new column names to `df.columns` by doing `df.columns = [list_of_new_column_names]` or we can use the `rename()` method to just modify a few of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HL5m6gkdCnFp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IF2uPoO3CnFp"
   },
   "source": [
    "# Using `apply()`, `map()`, and `applymap()`\n",
    "\n",
    "- `apply()`\n",
    "    - Apply a custom function to a Series.\n",
    "    - Useful for element-wise transformations.\n",
    "    - Example: `df['squared_numbers'] = df['numbers'].apply(lambda x: x ** 2)`\n",
    "\n",
    "- `map()`\n",
    "    - Transform Series elements based on a dictionary.\n",
    "    - Replaces elements with corresponding dictionary values.\n",
    "    - Example: `df['gender_mapped'] = df['gender'].map({'M': 'Male', 'F': 'Female'})`\n",
    "\n",
    "- `applymap()`\n",
    "    - Apply a custom function to every element in a DataFrame.\n",
    "    - Useful for element-wise transformations on entire DataFrames.\n",
    "    - Example: `df = df.applymap(lambda x: x.upper())`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9GCXyQaCnFp"
   },
   "source": [
    "### `Apply()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5x9Mnsf2CnFp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tufnyCEhCnFp"
   },
   "source": [
    "In the example above, we can see that to create a new column in pandas, we can simply assign a new Series or list to a new column name within the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUxYAKSmCnFp"
   },
   "source": [
    "To edit the information in a whole column in pandas, you can simply assign a new list or array of values to the column you want to modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fLDoQY8CnFp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkeub6iaCnFp"
   },
   "source": [
    "### `Map()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUVTS-heCnFp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gnL2Ka1CnFp"
   },
   "source": [
    "### `applyMap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8253U25CnFp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lkf3RKHCnFp"
   },
   "source": [
    "### More examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHL5Ki98CnFp"
   },
   "source": [
    "#### Comparing Map and Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwY5emsPCnFp"
   },
   "source": [
    "We have a column called \"Embarked\" containing three possible values: 'C', 'Q', and 'S'. We want to map these values to 0, 1 and 2. In this case, `apply()` with a lambda function would be complex due to the if-elif-else conditions, but `map()` can handle it more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGmgHLZrCnFp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMrgpWpHCnFq"
   },
   "source": [
    "Why is it a float?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQO0E7FOCnFq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vu6NEc-RCnFq"
   },
   "source": [
    "#### Calculating the length of the name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-r611CZCnFq"
   },
   "source": [
    "What if we wanted to create a new column with the length of the name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIKc7f_mCnFq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAqckF6YCnFq"
   },
   "source": [
    "#### Converting to float some columns with applymap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBb3GcyuCnFq"
   },
   "source": [
    "Lets look just as an example, how to make float all the following columns: \"PassengerId\", \"Survived\", \"Pclass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ks9Jf8NCnFq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUROZFl4CnFq"
   },
   "source": [
    "#### Modifying cloumns names with apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6V41iZbCnFq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnxMI1KsCnFr",
    "tags": []
   },
   "source": [
    "# Filtering Data\n",
    "\n",
    "One of the primary tasks in dataset analysis is filtering rows.\n",
    "\n",
    "When filtering DataFrames in Pandas, you can use boolean indexing to select specific rows based on certain conditions. Here's a step-by-step explanation:\n",
    "\n",
    "1. Identify the column(s) you want to use as a filter condition. For example, in `housing_df` the column named 'SalePrice'.\n",
    "\n",
    "2. Create a condition using a comparison operator (e.g., `>`, `<`, `==`, etc.) and the column(s) you want to filter. For instance, to filter all rows where the 'SalePrice' is greater than 10000, you would use `condition = housing_df['SalePrice'] > 10000`.\n",
    "\n",
    "3. Use the condition to filter the DataFrame. You can do this by passing the condition inside square brackets to the DataFrame. For example, `filtered_df = housing_df[condition]` will create a new DataFrame `filtered_df` containing only the rows where the 'SalePrice' is greater than 10000.\n",
    "\n",
    "Keep in mind that the condition should evaluate to a boolean Series with the same length as the DataFrame, indicating which rows to include (True) or exclude (False).\n",
    "\n",
    "You can also combine multiple conditions using logical operators like `&` for 'and' and `|` for 'or'. For instance, to filter rows where the 'SalePrice' is greater than 10000 and the 'FullBath' is more than 1, you can use `condition = (housing_df['SalePrice'] > 10000) & (housing_df['FullBath'] > 1)`.\n",
    "\n",
    "Filtering allows you to extract specific subsets of data from your DataFrame, making it easier to analyze and work with the data that meets your criteria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yS14iulsCnFr"
   },
   "source": [
    "### Creating a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DHeFIQECnFr",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAnQ3klmCnFr"
   },
   "source": [
    "### Filtering df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhDy-Y4jCnFr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWPewrwnCnFr"
   },
   "source": [
    "### Using multiple conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CasuVoTNCnFr",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0q-icRs4CnFr"
   },
   "source": [
    "# More Data Manipulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yA6YIRl-CnFr"
   },
   "source": [
    "## Setting the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OILJaZOxCnFr"
   },
   "source": [
    "To set an index in pandas, you can use the `set_index()` method of the DataFrame. This method allows you to specify which column you want to use as the index for the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUeSgS3kCnFs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IutbZIs2CnFs"
   },
   "source": [
    "## Adding/removing rows and/or columns\n",
    "\n",
    "To add or remove rows and/or columns from a pandas DataFrame, you can use the following methods:\n",
    "\n",
    "1. Adding rows:\n",
    "   - Use the `append()` method to add rows to the DataFrame.\n",
    "\n",
    "2. Removing rows:\n",
    "   - Use the `drop()` method with the row index or label to remove specific rows.\n",
    "\n",
    "3. Adding columns:\n",
    "   - Using `df[new_column]`, you simply assign a list, Series, or scalar value to the new column name\n",
    "   - Assign a new column to the DataFrame using bracket notation or the `assign()` method.\n",
    "\n",
    "4. Removing columns:\n",
    "   - Use the `drop()` method with the column name and `axis=1` to remove specific columns.\n",
    "   - Alternatively, you can use the `del` keyword to remove a column in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYoeacZRCnFs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yM4bideCnFs"
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmDQy2p3CnFs"
   },
   "source": [
    "1. Null Values:\n",
    "   - Null values (also known as missing values) can hinder data analysis and modeling.\n",
    "   - Use `isnull()` or `isna()` to check for null values in a DataFrame or Series.\n",
    "   - Use `any()` and `sum()` to efficiently assess data quality.\n",
    "   - Use `dropna()` to remove rows or columns with null values from a DataFrame.\n",
    "   - Parameters like subset, how, and thresh can control the behavior of dropping rows or columns.\n",
    "   - Use `fillna()` to replace null values with specific values, such as `mean()`, `median()`, or forward/backward fill.\n",
    "\n",
    "5. Formatting Data:\n",
    "   - Use `round()` and `format()` to format numeric values.\n",
    "   - Use f-strings, `format()` or % to format strings and use string methods like `lower()`, `upper()`, `title()`, `strip()`, `split()`, and `replace()`.\n",
    "\n",
    "6. Cleaning Column Names:\n",
    "   - Use df.columns to access column names.\n",
    "   - Modify column names using df.columns or `rename()`.\n",
    "\n",
    "7. Using `apply()`, `map()`, and `applymap()`:\n",
    "   - `apply()`: Applies a custom function to a Series.\n",
    "   - `map()`: Transforms Series elements based on a dictionary.\n",
    "   - `applymap()`: Applies a custom function to every element in a DataFrame.\n",
    "\n",
    "8. Filtering Data:\n",
    "   - Filter rows in a DataFrame using boolean indexing.\n",
    "   - Use comparison operators (<, >, ==) to create conditions.\n",
    "   - Combine multiple conditions using logical operators (& for 'and', | for 'or').\n",
    "\n",
    "9. Setting the Index:\n",
    "   - Use `set_index()` to set an index for the DataFrame.\n",
    "\n",
    "10. Adding/Removing Rows and Columns:\n",
    "   - Use `append()` to add rows to the DataFrame.\n",
    "   - Use `drop()` with the row index/label to remove specific rows.\n",
    "   - Use bracket notation, `assign()`, or `drop()` with axis=1 to add/remove columns."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "537.273px",
    "left": "27.9957px",
    "top": "110.824px",
    "width": "260px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
